---
title: "YOLO v3  Pytorch로 바닥부터 구현해보기 part.2"
layout: single
comments: true
categories:
  - Object Detection
  - Deep Learning
tags:
  - 딥러닝
  - Deeplearning
  - Object Detection
  - Pytorch
  - YOLO
use_math: true
---

이번 part.2에서는 YOLO v3 탐지기를 처음부터 구현해보는 튜토리얼이다.
저번 글에서 YOLO가 어떻게 작동하는지 설명했었다. 
그리고 이번 글에서는 파이토치를 통해서 YOLO에서 사용된 layer들을 구현해볼 것이다.

이 글에서 사용된 환경은 Python 3.5버전과 PyTorch 0.4버전이다.
전체 코드는 [이 Github](https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch)에서 찾아볼 수 있다.

다시 말하지만, 이 튜토리얼은 5개의 파트로 나누어져 있다.

Part 1 : [YOLO가 어떻게 작동하는지 이해하기.](https://anywhere133.github.io/object%20detection/deep%20learning/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98-YOLOv3_Part1)
Part 2 : YOLO의 신경망 구조의 layer들을 만들기.
Part 3 : 신경망의 순전파 과정을 구현하기.
Part 4 : Objectness Score Thresholding and Non-Maximum Suppression
Part 5 : 입/출력 파이프라인을 설계하기

### 시작하기

탐지기가 실행될 코드가 담길 폴더를 우선 생성하자.

그 다음, 그 폴더 안에 `darknet.py`을 만든다.
Darknet은 YOLO의 기반이 되는 구조의 이름이다.
이 파일은 YOLO 신경망을 생성할 코드를 포함하게 될 것이다.
그리고 `darknet.py`를 보충하기 위해 다양한 helper 함수를 담게 될 `util.py` 파일도 생성한다.

### Configuration File (설정 파일)

C로 작성된 공식적인 코드는 신경망을 만드는데 Configuration File을 사용한다.
*cfg* 파일은 블록 단위의 신경망 레이아웃을 설명해준다.
만약 caffe를 사용하는 사람이었다면, `.protxt`와 동일한 역할이라고 볼 수 있다.

우리는 신경망을 만들기 위해 저자가 배포하는 공식적인 *cfg* 파일을 사용할 것이다.
[여기](https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg)에서 다운로드 받아서 폴더 안에 `cfg` 폴더를 생성해 그 안에 넣어준다.

Configuration File을 열면, 다음과 같이 보일 것 이다.

````
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear
````

위에 보면 4개의 블록이 존재함을 알 수 있다.
3개의 convolution layer에 뒤이어 shortcut layer가 뒤따른다.
shortcut layer는 ResNet에서 사용된 skip connection과 같다.
YOLO에서는 5 종류의 layer가 존재한다.

#### Convolutional

```
[convolutional]
batch_normalize=1  
filters=64  
size=3  
stride=1  
pad=1  
activation=leaky
```

#### Shortcut

```
[shortcut]
from=-3  
activation=linear  
```

앞서 말했듯, shortcut layer는 ResNet에서 사용된 Skip Connection과 비슷하다.
`from` 파라미터가 -3이라는 의미는 shortcut layer의 출력이 
shortcut layer으로부터 이전 layer와 3번째 전의 layer의 feature map들의 합으로 나온다는 것이다.

#### Upsample

```
[upsample]
stride=2
```

Unsample layer는 bilinear upsampling을 사용하여 `stride`배 만큼 
이전 layer의 feature map을 upsamlpling한다.

#### Route

```
[route]
layers = -4

[route]
layers = -1, 61
```

route layer는 약간의 설명이 필요하다.
`layers` 속성는 하나를 받을 수도, 두 개의 값을 받을 수도 있다.

`layers`속성가 하나의 값을 받는 경우에는, 값이 인덱싱하는 layer의 feature map을 출력한다.
예를 들어 `layers` 값이 -4라면, route layer는 자신의 뒤쪽 방향 4번째 layer의 feature map을 출력하게 된다.

`layers` 속성가 두 개의 값을 받는 경우에는, 
두 값이 인덱싱하는 layer들의 feature map을 concatenate해서 출력한다.
예를들어 layer 값이 -1, 61이라면, 
route layer는 이전(-1) layer의 feature map과 61번째 layer의 feature map을 깊이 차원을 따라 연결한 것을 출력한다.

#### YOLO

```
[yolo]
mask = 0,1,2
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=80
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=1
```

YOLO layer는 part 1에서 설명한 detection layer와 대응된다.
`anchors`는 총 9개가 있지만 `mask` 속성의 값으로 인덱싱된 anchor만이 사용된다.
지금은 `mask`의 값이 0, 1, 2인데, 이는 1, 2, 3번 anchor가 사용된다는 의미이다.
이 것이 detection layer의 각 cell에서 3개의 box를 예측한다는 것을 설명할 수 있다.
종합적으로 3개의 scale의 detection layer에서 총 9개의 anchor를 가지게 된다.

#### Net

```
[net]
# Testing
batch=1
subdivisions=1
# Training
# batch=64
# subdivisions=16
width= 320
height = 320
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1
```

cfg에서 `net`이라 불리는 다른 종류의 블록이 있다.
그러나 이 것은 layer라고 말하지 않고, 
단순히 신경망의 입력과 훈련 파라미터에 대한 정보만을 설명한다.
이 블록은 YOLO의 순전파에서 사용되지 않지만, 
순전파에서 anchor를 조절하는 데 사용되는 신경망의 입력 크기와 같은 정보들을 제공한다.

### Configuration File 파싱하기

시작하기 전에, `darknet.py`의 상단에 필요한 라이브러리들을 import 해야한다.

```python
from __future__ import division

import torch 
import torch.nn as nn
import torch.nn.functional as F 
from torch.autograd import Variable
import numpy as np
```

cfg 파일의 경로를 입력으로 받는 `parse_cfg` 함수를 정의한다.

```python
def parse_cfg(cfgfile):
    """
    Takes a configuration file
    
    Returns a list of blocks. Each blocks describes a block in the neural
    network to be built. Block is represented as a dictionary in the list
    
    """
```

cfg를 파싱하기 위한 아이디어는 모든 블록들을 dict로 저장하는 것이다.
블록의 속성과 그 값들은 딕셔너리로 key-value 쌍으로 저장된다.
cfg를 파싱해나갈 때마다 dict인 변수 `block`에 key-value 쌍을 더해나가고,
해당 블록이 끝나면 `block`을 리스트 변수 `blocks`에 넣는다.
이 함수는 `blocks`를 반환하게 될 것이다.

```python
file = open(cfgfile, 'r')
lines = file.read().split('\n')                        # lines을 리스토로 저장
lines = [x for x in lines if len(x) > 0]               # 빈 줄을 제거 
lines = [x for x in lines if x[0] != '#']              # 주석 제거
lines = [x.rstrip().lstrip() for x in lines]           # 양 쪽의 공백을 제거
```

그 다음 반환할 리스트에 블록들을 넣는 루프를 만든다.

```
block = {}
blocks = []

for line in lines:
    if line[0] == "[":               # 새 블록의 시작을 체크하는 마크
        if len(block) != 0:          # 변수 block이 비워지지 않았다면, 이전 block의 값이 저장되있음을 의미
            blocks.append(block)     # add it the blocks list
            block = {}               # re-init the block
        block["type"] = line[1:-1].rstrip()     
    else:
        key,value = line.split("=") 
        block[key.rstrip()] = value.lstrip()
blocks.append(block)

return blocks
```

### building block을 만들기

`parse_cfg`를 사용하여 반환받은 block list를 통해, config file에 있는 블록들을 PyTorch module로 구성할 것이다.

앞서 언급한 5 종류의 layer들이 리스트에 존재한다.
PyTorch는 convolution과 upsample 종류의 pre-built layer를 제공한다.
나머지 layer에 대해서는 `nn.Module`을 통해서 직접 작성할 것이다.

`create_modules` 함수는 `parse_cfg` 함수로부터 반환받은 `blocks` 리스트를 입력받는다.

```python
def create_modules(blocks):
    net_info = blocks[0]     # 입력과 전처리에 대한 정보를 받는다.
    module_list = nn.ModuleList()
    prev_filters = 3
    output_filters = []
```

block의 리스트를 반복하기 전에, 신경망에 대한 정보를 저장하기 위한 변수 `net_info`를 정의해야 한다.

#### nn.ModuleList

`create_modules`는 `nn.ModuleList`를 반환하게 될 것이다.
이 클래스는 `nn.Module` 객체를 담고 있는 일반적인 리스트와 거의 비슷하다.
그러나 `nn.ModuleList`가 `nn.Module`의 멤버로 더해지게 되면,
`nn.ModuleList` 안의 `nn.Module` 객체의 모든 파라미터 s는 `nn.ModuleList`를 멤버로 하는 `nn.Module` 객체의 파라미터 s로 추가된다.

새 convolution layer를 정의할 때, 그 layer의 커널 차원을 정의해야한다.
cfg 파일에 의해 커널의 높이와 넓이는 제공되는 반면, 
커널의 깊이는 정확하게 이전 레이어에 나타나는 필터의 수 (또는 feature map의 깊이)이다.
이는 layer에서 convolution layer에 적용될 필터의 수를 계속 찾아야 할 필요가 있다는 것이다.
간단하게 변수 `prev_filter`를 사용하여 처리할 수 있다.
이미지의 RGB 채널에 대응하는 3으로 시작하면 된다.

Route layer는 이전 layer으로부터 feature map을 가져온다.
만약 convolution layer 바로 전에 route layer가 있다면, 
커널은 route layer가 가져올 feature map을 통해 적용될 것이다.
따라서 이전 layer의 필터 수를 추적하는 것이 아니라, 어떤 것이 선행하는 layer인지 찾아야 한다.
반복하기 위해서 각 블록의 결과 필터 수를 리스트 `output_filters`에 넣는다.

block 리스트를 반복하면서 각 block에 대한 PyTorch module을 만들자.

```python
 for index, x in enumerate(blocks[1:]):
        module = nn.Sequential()

        # 블록의 타입을 확인
        # 블록을 위한 새 module 생성
        # module list에 추가
```

`nn.Sequential` 클래스는 `nn.Module` 객체를 순차적으로 실행하기 위해서 사용된다.
cfg 파일을 보면, block이 하나 이상의 layer를 포함하는 경우를 볼 수 있다.
예를 들어, convolutional 타입의 블록은 batch norm layer와 leaky ReLU 활성화 layer가 convolution layer에 추가되어 있다.
이런 layer들을 `nn.Sequential`의 메소드 `add_module`을 사용해 하나로 묶는다.
아래는 convolutional layer와 upsample layer를 만드는 것에 대한 코드이다.

```python
if (x["type"] == "convolutional"):
            # layer에 대한 정보를 얻는다
            activation = x["activation"]
            try:
                batch_normalize = int(x["batch_normalize"])
                bias = False
            except:
                batch_normalize = 0
                bias = True

            filters= int(x["filters"])
            padding = int(x["pad"])
            kernel_size = int(x["size"])
            stride = int(x["stride"])

            if padding:
                pad = (kernel_size - 1) // 2
            else:
                pad = 0

            # convolutional layer를 추가한다.
            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias = bias)
            module.add_module("conv_{0}".format(index), conv)

            # batch norm layer를 추가한다.
            if batch_normalize:
                bn = nn.BatchNorm2d(filters)
                module.add_module("batch_norm_{0}".format(index), bn)

            # activation을 확인
            # YOLO의 activation은 Linear 또는 Leaky ReLU이다.
            if activation == "leaky":
                activn = nn.LeakyReLU(0.1, inplace = True)
                module.add_module("leaky_{0}".format(index), activn)

        # 만약 upsampling layer라면,
        # Bilinear2dUpsampling을 사용한다.
        elif (x["type"] == "upsample"):
            stride = int(x["stride"])
            upsample = nn.Upsample(scale_factor = 2, mode = "bilinear")
            module.add_module("upsample_{}".format(index), upsample)
```

#### Route Layer / Shortcut Layer

다음, Route layer와 Shortcut layer를 만드는 코드를 작성한다.

```python
# 만약 Route Layer이면
        elif (x["type"] == "route"):
            x["layers"] = x["layers"].split(',')
            # Route의 시작(속성 값이 1개인 경우)
            start = int(x["layers"][0])
            # Route의 끝(속성 값이 2개인 경우)
            try:
                end = int(x["layers"][1])
            except:
                end = 0
            # 양수로 되어 있는 경우
            if start > 0: 
                start = start - index
            if end > 0:
                end = end - index
            route = EmptyLayer()
            module.add_module("route_{0}".format(index), route)
            if end < 0:
                filters = output_filters[index + start] + output_filters[index + end]
            else:
                filters= output_filters[index + start]

        # Shortcut은 skip connection에 대응하는 layer
        elif x["type"] == "shortcut":
            shortcut = EmptyLayer()
            module.add_module("shortcut_{}".format(index), shortcut)
```

Route layer를 만드는 코드에 대해 어느 정도 설명이 필요해보인다.
우선 `layers` 속성에서 값을 추출해 `int`로 바꾼 후 `list`에 저장한다.
그 다음, `EmptyLayer`라는 말 그대로 빈 layer를 만든다.

````python
route = EmptyLayer()
````

`EmptyLayer`는 아래와 같이 정의된다.

````python
class EmptyLayer(nn.Module):
    def __init__(self):
        super(EmptyLayer, self).__init__())
````

#### 왜 빈 layer인가?

빈 layer가 아무 것도 하지 않아서 좀 이상해보일 수 있다.
Route Layer는 어떤 다른 layer가 연산을 수행하는 것처럼 동일하게 수행한다. 
(이전 layer를 앞으로 가져옴 / concatenate 연산)
PyTorch에서 새 layer를 정의할 때, `nn.Module`으로부터 상속받고 
`nn.Module` 객체의 `forward` 메소드에 layer가 수행할 연산을 적는다.

Route block에 대한 layer를 디자인하기 위해,
멤버의 속성 `layers`의 값으로 초기화된 `nn.Module` 객체를 만들어야 할 것이다.
그 다음, `forward` 메소드에 concatenate / feature map을 앞으로 가져오는 코드를 적는다.
최종적으로 신경망의 `forward`를 이 layer에서도 실행할 수 있게 된다.

그러나 주어진 concatenation 코드는 꽤 짧고 단순해 보인다. (`torch.cat`)
위와 같이 layer를 디자인하는 것은 판에 박힌 코드(Boiler plate code)를 증가시키는 불필요한 추상화로 이끌게 된다.
대신에 우리가 할 수 있는 것은 Route layer의 자리에 더미 layer를 놓고, darknet을 나타내는 `nn.Module` 객체의 `forward` 함수에 직접적으로 concatenation을 수행하는 것이다.

convolutionlay layer는 route layer 바로 앞에서 
이전 layer들의 (concatenate되었을 수도 있는) feature map에 커널을 적용한다.
아래의 코드는 route layer에 의해 출력되는 필터의 수를 유지하기 위한 `filters` 변수를 업데이트한다.

```python
if end < 0:
    # feature map을 concatenate하는 경우
    filters = output_filters[index + start] + output_filters[index + end]
else:
    filters= output_filters[index + start]
```

shortcut layer도 또한 굉장히 단순한 연산(더하기)을 수행하기 위해 빈 layer를 사용한다.
여기서는 단순히 이전 layer의 feature map에 바로 전 layer의 feature map을 더하는 것이기 때문에 `filters` 변수를 업데이트할 필요가 없다. 

#### YOLO Layer

드디어, YOLO Layer를 만드는 코드를 작성한다.

```python
# YOLO는 detection layer이다.
        elif x["type"] == "yolo":
            mask = x["mask"].split(",")
            mask = [int(x) for x in mask]

            anchors = x["anchors"].split(",")
            anchors = [int(a) for a in anchors]
            anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]
            anchors = [anchors[i] for i in mask]

            detection = DetectionLayer(anchors)
            module.add_module("Detection_{}".format(index), detection)
```

Bounding Box를 탐지하는 anchor를 가진 새 layer `DetectionLayer`를 정의하자.

detection layer는 다음과 같이 정의될 수 있다.

```python
class DetectionLayer(nn.Module):
    def __init__(self, anchors):
        super(DetectionLayer, self).__init__()
        self.anchors = anchors
```

루프의 마지막에서 저장를 한다.

```python
        module_list.append(module)
        prev_filters = filters
        output_filters.append(filters)
```

이 것은 루프의 body는 끝이 난다. `create_modules` 함수 끝에서 `model_list`와 `net_info`를 포함하고 있는 튜플을 반환받게 된다.

```python
return (net_info, module_list)
```

### 코드 테스트

`darkney.py`의 마지막에서 다음의 코드 라인을 입력하여, 전체 코드에 대해 테스트 해볼 수 있다.

```python
blocks = parse_cfg("cfg/yolov3.cfg")
print(create_modules(blocks))
```

실행하게 되면, 긴 리스트(정확히 106개의 항목)을 볼 수 있을 것이다.
그 리스트의 항목들은 다음과 같을 것이다.

```
.
.

  (9): Sequential(
     (conv_9): Conv2d (128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
     (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
     (leaky_9): LeakyReLU(0.1, inplace)
   )
   (10): Sequential(
     (conv_10): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
     (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
     (leaky_10): LeakyReLU(0.1, inplace)
   )
   (11): Sequential(
     (shortcut_11): EmptyLayer(
     )
   )
.
.
.
```

이 것이 이 파트의 끝이다.
다음 파트에서는 여기서 만든 블록들을 조립하여, 이미지로부터 출력까지 만들어 낼 것이다.
